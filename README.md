# Awesome Multimodal metaphor detection

## Dataset

|  Research Group  |  Title  |   Conference / Journal  |   Date   |   Code   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| 大连理工大学 <br> Dalian University of Technology | ![Star](https://img.shields.io/github/stars/DUTIR-YSQ/MultiMET.svg?style=social&label=Star) <br> [**MultiMET: A Multimodal Dataset for Metaphor Understanding**](https://aclanthology.org/2021.acl-long.249/) <br> | ACL 2021 Main Conference | 2021 | [Github](https://github.com/DUTIR-YSQ/MultiMET) |
| 大连理工大学 <br> Dalian University of Technology | ![Star](https://img.shields.io/github/stars/liaolianfoka/MET-Meme-A-Multi-modal-Meme-Dataset-Rich-in-Metaphors.svg?style=social&label=Star) <br> [**MET-Meme: A Multimodal Meme Dataset Rich in Metaphors**](https://dl.acm.org/doi/10.1145/3477495.3532019) <br> | SIGIR 2022 | 2022 | [Github](https://github.com/liaolianfoka/MET-Meme-A-Multi-modal-Meme-Dataset-Rich-in-Metaphors) |
| 谷歌 <br> Google | ![Star](https://img.shields.io/github/stars/metaclue/metaclue.github.io.svg?style=social&label=Star) <br> [**MetaCLUE: Towards Comprehensive Visual Metaphors Research**](https://openaccess.thecvf.com/content/CVPR2023/html/Akula_MetaCLUE_Towards_Comprehensive_Visual_Metaphors_Research_CVPR_2023_paper.html) <br> | 2023 CVPR | 2023 | [Github](https://github.com/metaclue/metaclue.github.io) |
| 大连理工大学 <br> Dalian University of Technology | ![Star](https://img.shields.io/github/stars/DUTIR-YSQ/MultiCMET.svg?style=social&label=Star) <br> [**MultiCMET: A Novel Chinese Benchmark for Understanding Multimodal Metaphor**](https://aclanthology.org/2023.findings-emnlp.409/) <br> | EMNLP 2023 Findings | 2023 | [Github](https://github.com/DUTIR-YSQ/MultiCMET) |
| 大连理工大学 <br> Dalian University of Technology <br> 皇家墨尔本理工大学 <br> Royal Melbourne Institute of Technology University | ![Star](https://img.shields.io/github/stars/DUTIR-YSQ/MultiMM.svg?style=social&label=Star) <br> [**Cultural Bias Matters: A Cross-Cultural Benchmark Dataset and Sentiment-Enriched Model for Understanding Multimodal Metaphors**](https://aclanthology.org/2025.acl-long.1275/) <br> | ACL 2025 Main Conference | 2025 | [Github](https://github.com/DUTIR-YSQ/MultiMM) |
| 大连理工大学 <br> Dalian University of Technology <br> 皇家墨尔本理工大学 <br> Royal Melbourne Institute of Technology University | ![Star](https://img.shields.io/github/stars/DUTIR-YSQ/EmoMeta.svg?style=social&label=Star) <br> [**EmoMeta: A Chinese Multimodal Metaphor Dataset and Novel Method for Emotion Classification**](https://dl.acm.org/doi/abs/10.1145/3701716.3735080) <br> | WWW 2025 Companion Proceedings | 2025 | [Github](https://github.com/DUTIR-YSQ/EmoMeta) |



## Model
|  Research Group  |  Title  |   Conference / Journal  |   Date   |   Code   |
|:--------|:--------:|:--------:|:--------:|:--------:|
|厦门大学 <br> Xiamen University | [**Multimodal metaphor detection based on distinguishing concreteness**](https://doi.org/10.1016/j.neucom.2020.11.051) | Neurocomputing | 14 March 2021 | - |
|苏州大学 <br> Soochow University | ![Star](https://img.shields.io/github/stars/xyz189411yt/C4MMD.svg?style=social&label=Star) <br> [**C4MMD: Exploring Chain-of-Thought for Multi-modal Metaphor Detection**](https://aclanthology.org/2024.acl-long.6/) <br> | ACL 2024 Main Conference | 2024 | [Github](https://github.com/xyz189411yt/C4MMD) |
|新疆大学 <br> Xinjiang University | [**VIEMF: Multimodal metaphor detection via visual information enhancement with multimodal fusion**](https://doi.org/10.1016/j.ipm.2024.103652) | Information Processing & Management | May 2024 | - |
|新疆大学 <br> Xinjiang University | [**SC-Net: Multimodal metaphor detection using semantic conflicts**](https://doi.org/10.1016/j.neucom.2024.127825) | Neurocomputing | 14 August 2024 | - |
|中国科学院自动化研究所 <br> Institute of Automation, Chinese Academy of Sciences <br> 中国科学院大学 <br> University of Chinese Academy of Sciences | ![Star](https://img.shields.io/github/stars/TIAN-viola/ImaRA.svg?style=social&label=Star) <br> [**ImaRA: An Imaginative Frame Augmented Method for Low-Resource Multimodal Metaphor Detection and Explanation**](https://aclanthology.org/2025.findings-naacl.220/) <br> | NAACL 2025 Findings | 2024 | [Github](https://github.com/TIAN-viola/ImaRA) |
|新疆大学 <br> Xinjiang University | [**iAMeta: Advancing multimodal metaphor detection using MLLMs and information debiasing**](https://doi.org/10.1016/j.inffus.2025.103348) | Information Fusion | December 2025 | - |
